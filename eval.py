# custom_taxi_env.py
import gym
import numpy as np
import time
import random
from IPython.display import clear_output

from xml.etree import ElementTree as ET
import importlib.util
import requests
import argparse

class DynamicTaxiEnv(gym.Wrapper):
    def __init__(self, grid_size=5, fuel_limit=50, randomize_passenger=True, randomize_destination=True, noise_level=0.1):
        self.grid_size = grid_size
        env = gym.make("Taxi-v3", render_mode="ansi")
        super().__init__(env)
        
        self.fuel_limit = fuel_limit
        self.current_fuel = fuel_limit
        self.randomize_passenger = randomize_passenger
        self.randomize_destination = randomize_destination
        self.noise_level = noise_level

        self.generate_random_map()

    def generate_random_map(self):
        """ éš¨æ©Ÿç”¢ç”Ÿç«™é»èˆ‡éšœç¤™ç‰© """
        self.stations = random.sample([(x, y) for x in range(self.grid_size) for y in range(self.grid_size)], 4)
        self.obstacles = random.sample([(x, y) for x in range(self.grid_size) for y in range(self.grid_size) if (x, y) not in self.stations], int(self.grid_size**2 * 0.2))
        
        self.station_labels = ['R', 'G', 'Y', 'B']
        self.station_map = {self.station_labels[i]: self.stations[i] for i in range(4)}

    def reset(self, **kwargs):
        obs, info = super().reset(**kwargs)  # Gym 0.26+ çš„æ¨™æº–å›å‚³å€¼
        self.current_fuel = self.fuel_limit
        self.generate_random_map()

        # è¨­å®šä¹˜å®¢ä½ç½®
        if self.randomize_passenger:
            self.passenger_loc = random.choice(self.stations)
        else:
            self.passenger_loc = self.stations[0]

        # è¨­å®šç›®çš„åœ°
        if self.randomize_destination:
            possible_destinations = [s for s in self.stations if s != self.passenger_loc]
            self.destination = random.choice(possible_destinations)
        else:
            self.destination = self.stations[1]

        # å–å¾— Agent ç›®å‰çš„ä½ç½®
        taxi_row, taxi_col, pass_idx, dest_idx = self.env.unwrapped.decode(obs)

        # è½‰æ› `pass_idx` èˆ‡ `dest_idx` ç‚º (x, y) åº§æ¨™
        passenger_x, passenger_y = self.passenger_loc
        destination_x, destination_y = self.destination

        # æ–°çš„ç‹€æ…‹è¡¨ç¤ºæ–¹å¼ (å¯æ³›åŒ–åˆ°ä¸åŒ `n Ã— n` åœ°åœ–)
        state = (taxi_row, taxi_col, passenger_x, passenger_y, destination_x, destination_y)

        return state, info  # âœ… ç¢ºä¿å›å‚³ç¬¦åˆ Gym 0.26+

    def step(self, action):
        if np.random.rand() < self.noise_level:  # è®“ agent æœ‰æ©Ÿç‡åšéŒ¯èª¤çš„å‹•ä½œ
            action = self.action_space.sample()

        # å–å¾— Agent ç›®å‰çš„ä½ç½®
        taxi_row, taxi_col, pass_idx, dest_idx = self.env.unwrapped.decode(self.env.unwrapped.s)

        # è¨ˆç®—ä¸‹ä¸€æ­¥ä½ç½®
        next_row, next_col = taxi_row, taxi_col
        if action == 0:  # Move South
            next_row = min(self.grid_size - 1, taxi_row + 1)
        elif action == 1:  # Move North
            next_row = max(0, taxi_row - 1)
        elif action == 2:  # Move East
            next_col = min(self.grid_size - 1, taxi_col + 1)
        elif action == 3:  # Move West
            next_col = max(0, taxi_col - 1)

        # **æª¢æŸ¥æ˜¯å¦æ’åˆ°éšœç¤™ç‰©**
        if (next_row, next_col) in self.obstacles:
            reward = -5  # æ’åˆ°éšœç¤™ç‰©
            self.current_fuel -= 1
            # ç‡ƒæ–™æª¢æŸ¥
            if self.current_fuel <= 0:
                return self.get_state(), reward -10, True, False, {}
            return self.get_state(), reward, False, False, {}

        # ç‡ƒæ–™æª¢æŸ¥
        if self.current_fuel <= 0:
            return self.get_state(), -10, True, False, {}

        # åŸ·è¡Œå‹•ä½œ
        self.current_fuel -= 1
        obs, reward, terminated, truncated, info = super().step(action)

        # èª¿æ•´ rewardï¼ˆç¬¦åˆæ–°è¦å‰‡ï¼‰
        if reward == 20:  # æˆåŠŸ `DROPOFF`
            reward = 50
        elif reward == -1:  # æ¯ä¸€æ­¥è¡Œå‹•æ‡²ç½°
            reward = -0.1
        elif reward == -10:  # éŒ¯èª¤ `PICKUP` æˆ– `DROPOFF`
            reward = -10

        # å›å‚³è‡ªè¨‚çš„ `state`
        return self.get_state(), reward, terminated, truncated, info

    def get_state(self):
        """ å–å¾—ç•¶å‰ state (é©ç”¨æ–¼ä¸åŒ `n Ã— n` åœ°åœ–) """
        taxi_row, taxi_col, _, _ = self.env.unwrapped.decode(self.env.unwrapped.s)
        passenger_x, passenger_y = self.passenger_loc
        destination_x, destination_y = self.destination
        return (taxi_row, taxi_col, passenger_x, passenger_y, destination_x, destination_y)

    def render_env(self, taxi_pos):
        """ é¡¯ç¤ºç’°å¢ƒç‹€æ…‹ï¼Œæ¨™ç¤º Agent ä½ç½® """
        clear_output(wait=True)

        grid = [['.'] * self.grid_size for _ in range(self.grid_size)]

        for label, pos in self.station_map.items():
            grid[pos[0]][pos[1]] = label
        
        for obs in self.obstacles:
            grid[obs[0]][obs[1]] = 'X'
        
        grid[self.passenger_loc[0]][self.passenger_loc[1]] = 'P'
        grid[self.destination[0]][self.destination[1]] = 'D'
        grid[taxi_pos[0]][taxi_pos[1]] = 'ğŸš–'

        for row in grid:
            print(" ".join(row))
        print("\n")

def run_agent(agent_file, env_config, render=False):
    spec = importlib.util.spec_from_file_location("student_agent", agent_file)
    student_agent = importlib.util.module_from_spec(spec)
    spec.loader.exec_module(student_agent)

    env = DynamicTaxiEnv(**env_config)
    obs, _ = env.reset()  # obs æ˜¯ (taxi_row, taxi_col, passenger_x, passenger_y, destination_x, destination_y)
    total_reward = 0
    done = False
    step_count = 0

    while not done:
        taxi_row, taxi_col, passenger_x, passenger_y, destination_x, destination_y = obs  # âœ… æ­£ç¢ºè§£åŒ… 6 å€‹å€¼

        if render:
            print(f"step={step_count}")
            env.render_env((taxi_row, taxi_col))
            time.sleep(0.5)

        action = student_agent.get_action(obs)  # ç¢ºä¿ `get_action(obs)` æ”¯æ´é€™å€‹ state æ ¼å¼
        obs, reward, done, _, _ = env.step(action)
        total_reward += reward
        step_count += 1

    print(f"Agent Finished in {step_count} steps, Score: {total_reward}")
    return total_reward

def parse_arguments():
    parser = argparse.ArgumentParser(description="HW1")

    parser.add_argument("--token", default="", type=str)

    args = parser.parse_args()
    return args

if __name__ == "__main__":
   
    args = parse_arguments()

    # retrive submission meta info from the XML file
    xml_file_path = 'meta.xml'

    # Parse the XML file
    tree = ET.parse(xml_file_path)
    root = tree.getroot()

    sub_name = ""

    # Find the 'info' element and extract the 'name' value
    for book in root.findall('info'):
        sub_name =  book.find('name').text

    ### Start of evaluation section
    env_config = {
        "grid_size": 6,
        "fuel_limit": 10,
        "randomize_passenger": True,
        "randomize_destination": True,
        "noise_level": 0.1
    }

    agent_score = run_agent("student_agent.py", env_config, render=True)
    print(f"Final Score: {agent_score}")
    ### End of evaluation section

    # push to leaderboard
    params = {
        'act': 'add',
        'name': sub_name,
        'score': str(agent_score),
        'token': args.token
    }
    url = 'http://localhost/drl_hw1/action.php'

    response = requests.get(url, params=params)
    if response.ok:
        print('Success:', response.text)
    else:
        print('Error:', response.status_code)